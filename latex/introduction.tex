%!TEX root = doe.tex

For all its progress---more nuanced arguments, more useful theories, bigger data and more systematic ways to analyze them---international relations remains, in many ways, a study of power.
This is best reflected in the questions that have endured.
Is the world safer when power is concentrated in a few states or broadly distributed \citep{waltz}?
How does the balance of power between states, or shifts thereof, affect the likelihood of war \citep{organski1980,powell1999,powell2006war}?
Do international organizations allow states to gain benefits they would not receive from power politics alone \citep{keohanenye}?
Without good measures of power, we cannot provide good empirical answers to these fundamental questions.
Consequently, the importance of measuring power to the study of international politics cannot be overstated.

Like many other important concepts in political science, power cannot be measured directly.
Indeed, measurement problems in political science often entail the construction of proxies.
Recent advances in computing and modeling have allowed political scientists to build sophisticated, data-driven proxies for variables as diverse as legislator ideology \citep{clinton2004}, judicial independence \citep{linzer2014}, and country regime types \citep{jackman2008}.
But despite the centrality of power to many important hypotheses in international relations, its measurement has seen far less innovation.\footnote{%
  A recent exception is \citet{Arena:2012}.
}
In this article, we remedy this by devising a new, data-driven approach for measuring power.
Specifically, we aim to learn what combination of observable material capability variables best predicts international dispute outcomes.

We are particularly interested in the crystallization of power that animates the bargaining model of war:  the probability that one state will defeat another in case of militarized conflict, commonly denoted $p$.
This outcome expectation is central to the standard bargaining model \citep{fearon1995}, where it serves as the operationalization of power when dismissing the mutual optimism hypothesis or when unearthing the commitment problem that arises due to shifts in power over time.
The expected outcome of conflict also serves as the main concept of power in \citeapos{Slantchev:2003ka} theory of war termination and in \citeapos{powell2006war} model of commitment problems.
In other words, to study power---at least while motivated by the bargaining model---we must study what shapes dispute outcomes.

We focus on military capabilities as determinants of expected dispute outcomes.
We do so for two reasons.
First, there is a longstanding precedent of starting from the material foundations of power, a practice most commonly associated with historians and theorists in the realist camp \citep{morgenthau,taylor,carr}.
And as \citet[46]{beckley2010economic} observes, even ``[l]iberals and constructivists often conceptualize military power in material terms when refuting its causal significance.''
Second, and of more relevance for the current empirical literature, our focus on the contributions of material capabilities follows the example set by most existing efforts to measure power in the international sphere, starting with the work by \citet{singer1972}.
Most current approaches use the Correlates of War Composite Index of National Capabilities (CINC) score, which combines material factors related to industrialization, wealth, population, and, of course, militarization.

Despite the innovations in measurement in various fields, political scientists have not reached a consensus on what makes for a good proxy, nor is there a common evaluatory metric.
We argue for a predictive criterion:  if the concept of interest is supposed to be associated with some observable outcome, then its proxy should predict the outcome well.\footnote{%
  By prediction, we mean out-of-sample prediction, with data not used to construct the proxy itself.
}
Simple as it may seem, this commitment to prediction highlights important issues.
Like Ulysses or Goldilocks, the proxy maker must strike a delicate balance.
She must learn from the data to construct the measure, else it will fail to capture important dimensions of the concept under study.
\emph{A priori} measures like summed rating scales suffer from this \emph{underfitting} problem, as they fail to take advantage of the wealth of data scholars now possess.
But the analyst who employs a data model for proxy construction faces pitfalls, too.
She may misidentify chance features of her data as systematic, a problem called \emph{overfitting}.
A good proxy should fit the data well, but not so well that it fails to generalize.
An underfit proxy will, of course, be a poor predictor, but so too will a data-driven proxy that maximizes in-sample fit at the expense of generalizability.
Our predictive criterion balances these two considerations.

So too does our methodology.
Supervised learning techniques, having been designed to navigate the straits between underfitting and overfitting, are ideal for data-driven proxy construction.
Machine learning models are flexible enough to analyze relationships far more complex than possible in ordinary regression or measurement models, but they also guard against connecting the dots too aggressively or misinterpreting noise in the data as a complex relationship.
To develop an optimal model for out-of-sample prediction, an analyst simply chooses appropriate tuning parameters, usually by a method like cross-validation that estimates prediction error \citep{Efron:2012es}.
Our approach mirrors that of \citet{Hill:2014ki}, who use cross-validation to assess the relative predictive power of many variables all thought to affect the same outcome.
Our focus, however, is on constructing variables rather than comparing them.

By the predictive criterion, a good measure of relative military power ought to predict dispute outcomes well.
We show that the standard measure, the ratio of CINC scores, predicts militarized dispute outcomes terribly---only 1~percent better than random guessing.
Our new proxy, the Dispute Outcome Expectations (DOE) score, is much better, providing a 20~percent predictive improvement.
It is surprising that the standard measure does so poorly by this criterion, given its ubiquitousness.
As we document below, dozens of recent publications in international relations use CINC-derived measures as proxies for power.
Our use of modern machine learning tools allows us to yield a superior measure from the same data underlying the usual measure.
In addition, the DOE score is interpretable as a probability, just like the bargaining concept of $p$ that animates our approach.

In the course of developing the DOE score, we gain several broad insights about power.
Most fundamentally, material capabilities indeed matter in shaping dispute outcomes, as we explain a substantial amount of variation with a small set of material variables.
This basic result contrasts with previous studies finding no effect of material capabilities \citep{Cannizzo:1980vz,Maoz:1983cw} and reinforces those that conclude capabilities affect victory \citep{wartrap,Stam:1996wl,Sullivan:2012vi}.
We go further to assess which of the CINC components matters most.
Our results suggest that energy consumption is the strongest individual predictor of dispute outcomes.
Surprisingly, military personnel and expenditures matter less on their own.
However, it appears that the effect of these explicitly military components has evolved over the years, while energy consumption's effects have remained more static.

We then go on to demonstrate the DOE score's usefulness to international relations scholars.
We replicate \citeapos{reed2008war} empirical test of Powell's~\citeyearpar{powell1996stability,powell1999} model of the relationship between relative power, the distribution of benefits between states, and the likelihood of conflict.
When we substitute DOE scores in for \citeauthor{reed2008war}'s CINC-based proxy of $p$, the resulting model fits better and predicts better out-of-sample.
More to the point, we extract an important new finding.
Whereas \citeauthor{reed2008war} conclude that the probability of conflict is sometimes greatest between states of equal power---namely, when the distribution of benefits is highly unequal---we find that this is never the case.
The probability of war is always maximized when the state that is worse off under the status quo has a preponderance of power.

Interesting as these results are, it remains that most empirical practitioners only include a capability ratio as a control variable while modeling a wide variety of dependent variables (often the onset of conflict, but sometimes other things).
We take our replication further to see whether the DOE score would be helpful for these scholars as well.
We reanalyze 18 such empirical models to see whether they fit better when we replace the standard proxy with DOE scores.
Since these studies examine outcomes besides the one we use to construct our proxy, there is no guarantee that our new proxy will do better.
Nonetheless, we yield an improvement in fit in 14 of the 18 cases.
In the 14 improved cases, the DOE variables are always jointly significant, whereas the original CINC-based measures of power are jointly insignificant about half the time.
Moreover, in two of these cases the main substantive hypothesis is no longer supported in the replicated model.
We thereby show how using a poor proxy for relative power, even as a control variable, can lead scholars to understate the impact of military power and to reach conclusions not supported by the data.

The paper proceeds in five sections.
In the first, we lay out our general argument about proxy construction and its application to the case of military power.
Section~\ref{sec:methods} describes the data and methods we use to construct a new proxy for expected dispute outcomes.
In Section~\ref{sec:scores}, we discuss the advantages and disadvantages of our measure.
Section~\ref{sec:replications} contains the results of our replications and advice for using the DOE score.
The final section addresses next steps and concludes.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "doe"
%%% End:
