\documentclass[11pt,oneside]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{sectsty}
\usepackage{tikz}
\usepackage[labelsep=period,font=small,labelfont=bf]{caption}
\usepackage[charter]{mathdesign}
\usepackage[scaled]{helvet}
\usepackage{pdflscape}
\usepackage{afterpage}
\usepackage[hyphens]{url}
\usepackage[colorlinks=true,citecolor=black]{hyperref}

% Highlighted notes
\usepackage{xcolor}
\usepackage{soul}
\newcommand{\note}[1]{\hl{[#1]}}

% Math commands
\DeclareMathOperator{\CVL}{CVL} % CV loss
\DeclareMathOperator{\CINC}{CINC} % CINC function

% Section heading styling
\allsectionsfont{\sffamily}

% BibTeX
\usepackage{natbib}
\renewcommand{\harvardurl}[1]{\textbf{URL:} \url{#1}}

\title{
  Capability Ratios Predict Nothing%
  \thanks{%
    We thank Zach Jones and Marc Ratkovic for helpful discussions and advice.
    Bryan Rooney provided excellent research assistance.
    We also thank the authors listed in Table~\ref{tab:replications} for making their replication data publicly available.
    Replication data and DOE scores are available at \url{https://dataverse.harvard.edu/dataverse/crpn}, and replication code and a version history of the project are available at \url{https://github.com/brentonk/crpn}.
  }%
}
\author{%
  Robert J. Carroll%
  \thanks{%
    Assistant Professor, Department of Political Science, Florida State University.  Email:  \nolinkurl{RobCarrollFSU@gmail.com}.
  }%
  \and%
  Brenton Kenkel%
  \thanks{
    Assistant Professor, Department of Political Science, Vanderbilt University.
    Email: \nolinkurl{brenton.kenkel@vanderbilt.edu}.
  }%
}

\begin{document}

\maketitle

\begin{abstract}
  Modern approaches to political measurement have generally ignored the importance of out-of-sample predictive performance. 
  This is problematic for two reasons; first, many of the abstractions scholars attempt to proxy for are themselves expectations; and second, the resulting measures are prone to overfitting. 
  We advocate a data-driven approach to measurement based on the train-validate-test paradigm from machine learning. 
  We demonstrate the effectiveness of the approach as it applies to proxying the expected outcome of militarized interstate disputes. 
  We find that the traditional ratio of capability indices has almost no predictive power relative to null models. 
  Conversely, the score we construct via our approach---the Dispute Outcome Expectations score, or DOE---improves out-of-sample predictive performance. 
  This holds even though our approach introduces no new covariates to the analysis, indicating the usefulness of our methodological approach.
  In replications of 18 empirical studies of international relations, we find that replacing standard capability measures with DOE scores usually improves both in-sample and out-of-sample goodness of fit.
\end{abstract}

\clearpage


\input{introduction}


\input{prediction}


\input{discontents}


\input{methods}


\input{replications}


\input{conclusion}


\clearpage
\appendix
\input{appendix}

\newpage
\bibliographystyle{apsr}
\bibliography{doebib}


\end{document}
