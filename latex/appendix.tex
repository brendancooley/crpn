%!TEX root = doe.tex

\section{Appendix}

\subsection{National Material Capabilities Data}

Our predictors are taken from the National Material Capabilities (v4.0) dataset from the Correlates of War project \citepapp{singer1972}.\footnote{%
  Downloaded from \url{http://correlatesofwar.org/data-sets/national-material-capabilities/nmc-v4-data/at_download/file}.
}
The dataset contains observations on six variables for 14,199 country-years from 1816 to 2007.
For details on the variables and their measurement, see the NMC Codebook.\footnote{%
  Available at \url{http://correlatesofwar.org/data-sets/national-material-capabilities/nmc-codebook/at_download/file}.
}
Table~\ref{tab:summary} lists the proportions of zeroes and missing values among each variable.

\begin{table}[htp]
  \centering
  \input{tab-summary}
  \caption{
    Proportions of zeroes and missing values in each National Military Capability component variable.
  }
  \label{tab:summary}
\end{table}

All six variables are right-skewed.
Since five of the six variables are sometimes zero-valued (though all are non-negative), a logarithmic transformation is not appropriate.
Instead, to correct for skewness, we apply an inverse hyperbolic sine transformation \citepapp{Burbidge:1988gu} to each component:
\begin{equation}
  \label{eq:asinh}
  h(x, \theta)
  =
  \sinh^{-1} (\theta x)
  =
  \log \left(
    \theta x + \sqrt{(\theta x)^2 + 1}
  \right).
\end{equation}
We set the scale~$\theta$ separately for each component variable with the aim of making the transformed variable approximately normally distributed.
For each variable, we choose the value of $\theta \in \{2^d\}_{d=-10}^{10}$ that minimizes the Kolmogorov--Smirnov test statistic \citepapp{MasseyJr:2012jo} against a normal distribution with the same mean and variance.
Table~\ref{tab:summary} gives the scale selected for each component.
We use the transformed components in both the multiple imputation (see below) and the super learner training.

\subsection{Militarized Interstate Dispute Data}

Our sample and outcome variable are taken from the Militarized Interstate Disputes (v4.1) dataset from the Correlates of War project \citepapp{Palmer:2015hp}.\footnote{%
  Downloaded from \url{http://correlatesofwar.org/data-sets/MIDs/mid-level/at_download/file}.
}
The dataset records the participants and outcomes of interstate disputes from 1816 to 2010.
To avoid the problem of aggregating capabilities across multiple states, we exclude disputes with more than one state on either side.
We drop disputes that end in an outcome other than one side winning, one side yielding, or a stalemate;\footnote{%
  For details on other kinds of outcomes, see the MID Codebook.
}
we then collapse ``A Wins'' and ``B Yields'' into a single coding, and similarly for ``B Wins'' and ``A Yields.''
Finally, since the capabilities data only run through 2007, we exclude disputes that end after 2007.
In the end, we have $N = 1{,}740$ cases.

For each dispute in our dataset, we code the participating countries' capabilities using the values in the year the dispute began.
About 17~percent of disputes have at least one missing capability component for at least one participant.

\subsection{Multiple Imputation}

As noted above, all of the National Material Capabilities variables contain some missing values.
Following standard practice, we multiply impute the missing observations.
We perform the imputations via the \texttt{Amelia} software package \citepapp{pkg-Amelia}.

Rather than just impute the missing values in the final dataset of disputes, we impute the entire National Material Capabilities dataset.
This allows us to fully exploit the dataset's time-series cross-sectional structure in the imputation process \citepapp{honaker_what_2010}.
We include in the imputation model a cubic polynomial for time, interacted with country dummy variables.
As this results in an explosion in the number of parameters in the imputation model, we then impose a ridge prior equal to 0.1 percent of the observations in the dataset (see Section~4.7.1 of the \texttt{Amelia} package vignette).
We enforce the constraint that every imputed value be non-negative.
Finally, we impose an observation-level prior with mean zero and variance equal to that of the observed values of the corresponding component variable for every missing cell that meets the following criteria:
\begin{itemize}
  \item There are no non-zero observed values in the time series preceding the cell
  \item The first observed value that comes after the cell is zero
\end{itemize}
So, for example, if a country's urban population is zero from 1816 to 1840, missing from 1841 to 1849, and zero in 1850, we would impose this form of prior on the 1841--1849 values.
Diagnostic time series plots of observed versus imputed values within each data series, generated by the \texttt{tscsPlot()} function in \texttt{Amelia}, will be made available in the project's Dataverse.

The presence of missing data also complicates the calculations of country-by-country proportions of the total amount of each component by year.
One option is to recompute the annual totals in each imputed dataset, so that the resulting data will be logically consistent---in particular, all proportions will sum to one.
The drawback of this approach is that virtually every observation of the proportions will differ across the imputed datasets, even for countries with no missing data, since the annual totals will differ across imputations.
An alternative approach is to compute the annual totals using only the observed values.
The advantage is that non-missing observations will not vary across imputed datasets; the downside is that the proportions within each imputation will generally sum to more than one.
For our purposes in this paper, we think it is preferable to reduce variation across imputations, even at the expense of some internal consistency in the imputed datasets, so we take the latter approach: annual totals are the sums of only the observed values.

We impute $I = 10$ datasets of national capabilities according to the procedure laid out above, and we merge each with the training subset of our dispute data to yield $I$ training data imputations.
We run the super learner separately on each imputation, and our final model is an (unweighted) average of the $I$ super learners.

After training is complete, we run into missing data problems once again when calculating DOE scores.
To calculate predicted probabilities for dyads with missing values, we calculate a \emph{new} set of $I = 10$ imputations of the capabilities data and take an (unweighted) average of our model's predictions across the imputations.

\subsection{Super Learner Candidate Models}

We use the R statistical environment \citepapp{pkg-R} for all data analysis.
We fit, cross-validate, and calculate predictions from each candidate model through the \texttt{caret} package \citepapp{pkg-caret}.
We then construct the super learner by solving~\eqref{eq:super-learner} via base R's \texttt{constrOptim()} function for optimization with linear constraints.
Candidate models were drawn from \citet{Wu:2007ev} and \citet{FernandezDelgado:2014ul}.
Four of the algorithms named in \citet{Wu:2007ev}---$k$-means, Apriori, expectation maximization, and PageRank---are not suited for the prediction task at hand.
We also excluded AdaBoost due to long computation time and naive Bayes due to poor performance in initial tests.
Further details about each candidate model are summarized below.

\begin{itemize}
  \sloppy

  \item Ordered Logit \citepapp{McKelvey:2010gv}
  \begin{description}
    \item[Package] \texttt{MASS} \citepapp{pkg-MASS}
    \item[Tuning Parameters] None
    \item[Notes] In the ``Year'' models, the year of the dispute is included directly and interacted with each capability variable
  \end{description}

  \item C5.0 \citepapp{Quinlan:2015uc}
  \begin{description}
    \item[Package] \texttt{C50} \citepapp{pkg-c50}
    \item[Tuning Parameters] ~
    \begin{itemize}
      \item Number of boosting iterations (\texttt{trials}): selected via cross-validation from $\{1, 10, 20, 30, 40, 50\}$
      \item Whether to decompose the tree into a rule-based classifier (\texttt{model}): selected via cross-validation
      \item Whether to perform feature selection (\texttt{winnow}): selected via cross-validation
    \end{itemize}
  \end{description}

  \item Support Vector Machine \citepapp{Cortes:1995ie}
  \begin{description}
    \item[Package] \texttt{kernlab} \citepapp{pkg-kernlab}
    \item[Tuning Parameters] ~
    \begin{itemize}
      \item Kernel width (\texttt{sigma}): selected via cross-validation from $\{0.2, 0.4, 0.6, 0.8, 1\}$
      \item Constraint violation cost (\texttt{C}): selected via cross-validation from $\{\frac{1}{4}, \frac{1}{2}, 1, 2, 4\}$
    \end{itemize}
    \item[Notes] ~
    \begin{itemize}
      \item Radial basis kernel
      \item All predictors centered and scaled to have zero mean and unit variance
    \end{itemize}
  \end{description}

  \item $k$-Nearest Neighbors \citepapp{Cover:1967jq}
  \begin{description}
    \item[Package] \texttt{caret} \citepapp{pkg-caret}
    \item[Tuning Parameters] ~
    \begin{itemize}
      \item Number of nearest neighbors to average (\texttt{k}): selected via cross-validation from $\{25, 50, \ldots, 250\}$
    \end{itemize}
    \item[Notes] All predictors centered and scaled to have zero mean and unit variance
  \end{description}

  \item CART \citepapp{Breiman:1984tu}
  \begin{description}
    \item[Package] \texttt{rpart} \citepapp{pkg-rpart}
    \item[Tuning Parameters] ~
    \begin{itemize}
      \item Maximum tree depth (\texttt{maxdepth}): selected via cross-validation from $\{2, 3, \ldots, 9, 10\}$ (only up to 9 for models without year included)
    \end{itemize}
  \end{description}

  \item Random Forest \citepapp{Breiman:2001fb}
  \begin{description}
    \item[Package] \texttt{randomForest} \citepapp{pkg-randomForest}
    \item[Tuning Parameters] ~
    \begin{itemize}
      \item Number of predictors randomly sampled at each split (\texttt{mtry}): selected via cross-validation from $\{2, 4, \ldots, 12\}$
    \end{itemize}
    \item[Notes] 1,000 trees per fit
  \end{description}

  \item Averaged Neural Nets \citepapp{Ripley:1996vd}
  \begin{description}
    \item[Package] \texttt{nnet} \citepapp{pkg-MASS}, \texttt{caret} \citepapp{pkg-caret}
    \item[Tuning Parameters] ~
    \begin{itemize}
      \item Number of hidden layer units (\texttt{size}): selected via cross-validation from $\{1, 3, 5, 7, 9\}$
      \item Weight decay parameter (\texttt{decay}): selected via cross-validation from $\{10^0, 10^{-1}, 10^{-2}, 10^{-3}, 10^{-4}\}$
    \end{itemize}
    \item[Notes] Creates an ensemble of 10 neural nets, each initialized with different random number seeds
  \end{description}
\end{itemize}

\subsection{Replications}

\newcommand{\coef}[1]{\beta[\text{#1}]}

The following list contains basic information about each model in the replication study.
We carry out logistic and probit regressions via \texttt{glm()} in base R \citepapp{pkg-R}, multinomial logit via \texttt{multinom()} in the \texttt{nnet} package \citepapp{pkg-MASS}, ordered probit via \texttt{polr()} in the \texttt{MASS} package \citepapp{pkg-MASS}, and heteroskedastic probit via \texttt{hetglm()} in the \texttt{glmx} package \citepapp{pkg-glmx}.

\begin{table}[p]
  \centering
  \small
  \input{tab-replications-appendix}
  \caption{
    Full results of replication analyses.
    Cross-validation results are from repeated 10-fold cross-validation; those marked $\dag$ are repeated 10 times, all others 100 times.
  }
  \label{tab:replications-appendix}
\end{table}

\input{list-replications}


\bibliographystyleapp{apsr}
\bibliographyapp{doebib}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "doe"
%%% End:
