%!TEX root = doe.tex

\section{Conclusion}
\label{sec:conclusion}

We hope that our efforts will be of use both for the DOE scores we provide and for the theoretical merits of our general argument.
The DOE scores outperform the extant proxy---the CINC-based capability ratio---in a number of important ways.
In pure terms, the DOE score more closely relates to what international relations scholars care about: the expected outcome of a dispute between two nations.
On the practical side, our replications suggest that the DOE score is a better contributor to the usual battery of variables included in the ever-expanding universe of international relations regressions.
We hope, then, that it will find use as scholars advance and test new claims.

Though it represents a massive improvement over the \emph{status quo}, the DOE score could still be improved.
We have only included those variables that could be extracted from the data used to construct the capability ratio---namely, the six Correlates of War National Material Capabilities variables.
We did so consciously, as we wanted to demonstrate that our method could improve measures holding the covariates fixed.
Having made our point, we look forward to seeing what the future holds for coming versions of DOE when new data is brought to bear on the problem.
Since our underlying method uses well-programmed algorithms, anybody with a computer---and some patience!---could create a new version with new covariates.

On the methodological side, we believe that our data-driven approach to measurement will prove useful for those wishing to proxy for other quantities.
All one needs is a set of predictor variables $X$ and some outcome of interest $Y$---the procedure we provide to produce a mapping~$f$ from $X$ to $Y$ will work.
Just as with introducing new covariates in any given application, future scholars can improve their proxies by including new models for evaluation in the super learner.
Our application tasked us to create a proxy of a probabilistic expectation, and similar applications provide a natural starting point for our method.
Doing so, however, requires good theory for just what it is that we hope to predict with our abstractions. 
As such theories continue to develop, we hope political scientists across subfields will turn their attention to prediction and flexibility as they construct new measures and improve existing ones.

We would like to conclude with a still broader point.
\citet{Breiman:2001fd} argues that statistical modelers fall into one of two cultures: data modelers, who interpret models' estimates after assessing overall quality via in-sample goodness of fit; and algorithmic modelers, who seek algorithms that predict responses as well as possible given some set of covariates.
The method we advance is certainly algorithmic.
Our decision to adopt algorithmic modeling based on prediction, however, was not culture-driven---it was purpose-driven \citep{clarke2012}.
Most simply, prediction matters for measurement, so algorithmic tools should play a larger role.
But as we show in the replication analysis, an algorithmically constructed proxy can be useful to include in traditional models.
As new problems emerge and new solutions arise to solve them, we believe methodological pragmatism will be an important virtue.
We neither expect nor encourage empirical political science to turn its focus from causal hypothesis testing to prediction.
But good hypothesis testing depends on good measures, and sometimes the best way to build a measure is to assume the persona of the algorithmic modeler.
By doing just that, this paper has developed one measure that improves on the previous state of the art along a number of dimensions.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "doe"
%%% End:
